{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f039323-8204-4db6-b293-dcde7d2f499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccea4dba-4069-4658-ac2a-da29fd972070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "print(device)\n",
    "batch_size = 64\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37db19be-4225-49e0-b2df-2e9e37dde4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (layer3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implement Neural Network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        return x\n",
    "standard_trained_model = NeuralNetwork().to(device)\n",
    "standard_trained_model.train()\n",
    "model = NeuralNetwork().to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c43a6aa-bda1-45d5-81be-5899bca15b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs):\n",
    "    # TODO: implement this function that trains a given model on the MNIST dataset.\n",
    "    # this is a general-purpose function for both standard training and adversarial training.\n",
    "    # (toggle enable_defense parameter to switch between training schemes)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    for i in range(num_epochs):\n",
    "        for idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #if idx % 10 == 0:\n",
    "                #print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108a5de1-4066-4da3-a4eb-09314673dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(standard_trained_model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722f7c69-8522-4f9d-bf23-1191c3d08f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print('\\n Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96316aa5-135c-48d7-a145-4c8ca7345778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 6836/10000 (68%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_test(standard_trained_model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47690e97-e5b0-4f3b-82c2-47f543dbf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, x, eps, y):\n",
    "    #TODO: implement this as an intermediate step of PGD\n",
    "    # Notes: put the model in eval() mode for this function\n",
    "    model.eval()\n",
    "    x = x.clone().detach()\n",
    "    x.requires_grad = True\n",
    "    model_output = model(x)\n",
    "    entropy_loss = nn.CrossEntropyLoss()\n",
    "    loss = entropy_loss(model_output, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    loss_grad = x.grad.data\n",
    "    sign_loss_grad = loss_grad.sign()\n",
    "    eta = eps*loss_grad.sign()\n",
    "    perturbed_output = x+eta\n",
    "    perturbed_output = torch.clamp(perturbed_output, 0, 1)\n",
    "    return perturbed_output\n",
    "\n",
    "def pgd_untargeted(model, x, y, k, eps, eps_step):\n",
    "    #TODO: implement this \n",
    "    # Notes: put the model in eval() mode for this function\n",
    "    # x: input image\n",
    "    # y: ground truth label for x\n",
    "    # k: steps of FGSM\n",
    "    # eps: projection region for PGD (note the need for normalization before projection, as eps values are for inputs in [0,1])\n",
    "    # eps_step: step for one iteration of FGSM\n",
    "    model.eval()\n",
    "    adv=x\n",
    "    for i in range(k):\n",
    "        adv = fgsm(model, adv, eps_step, y)\n",
    "        #clipping\n",
    "        x_adv = torch.min(x + eps, torch.max(x-eps, adv))\n",
    "    x_adv = torch.clamp(x_adv, 0 ,1)\n",
    "    return adv\n",
    "#return adverserial examples\n",
    "@lru_cache(maxsize=60000) \n",
    "def pgd_untargeted_batch(model, inputs, targets, eps):\n",
    "    k=3\n",
    "    perturbed_inputs = []\n",
    "    for i in range(len(inputs)):\n",
    "        x = inputs[i]\n",
    "        y = targets[i]\n",
    "        perturbed_data = pgd_untargeted(model, x, torch.atleast_1d(y), k, eps, eps)\n",
    "        perturbed_inputs.append(perturbed_data)\n",
    "        \n",
    "    return torch.cat(perturbed_inputs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "153acc03-07d8-4434-9e62-b111581d9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ibp(model, num_epochs, eps, kappa):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    for i in range(num_epochs):\n",
    "        for idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            output = model(data)\n",
    "            standard_loss = nn.CrossEntropyLoss()(output, target)\n",
    "            total_loss = standard_loss\n",
    "            adv_input = pgd_untargeted_batch(standard_trained_model, data, target, eps)\n",
    "            robust_output = model(adv_input)\n",
    "            robustness_loss = nn.CrossEntropyLoss()(robust_output,target)\n",
    "            total_loss = (1-kappa)*robustness_loss + kappa*standard_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            if idx % 100 == 0:\n",
    "                print(' [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    idx * len(adv_input), len(train_loader.dataset),\n",
    "                    100. * idx / len(train_loader), total_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba0ccb36-6447-43ac-8436-8886451b9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_robustness(model, attack='pgd', eps=0.1):\n",
    "    # TODO: implement this function to test the robust accuracy of the given model\n",
    "    # use pgd_untargeted() within this function\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, targets in test_loader:\n",
    "        data,targets = data.to(device), targets.to(device)\n",
    "        if attack == 'pgd':\n",
    "            total +=len(data)\n",
    "            ori_output = model(data)\n",
    "            ori_prediction = ori_output.argmax(1, keepdim=True)\n",
    "            correct+=ori_prediction.eq(targets.view_as(ori_prediction)).sum().item()\n",
    "        total +=len(data)\n",
    "        pgd_data = pgd_untargeted_batch(model, data, targets, eps)\n",
    "        pgd_output = model(pgd_data)\n",
    "        prediction_after_attack = pgd_output.argmax(dim=1, keepdim=True)\n",
    "        correct+=prediction_after_attack.eq(targets.view_as(prediction_after_attack)).sum().item()\n",
    "    print('\\n Eps: {}, Robustness: {}/{} ({:.0f}%)\\n'.format(\n",
    "        eps, correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1217e8e-57c9-4478-acdf-fcf318fc4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in (0.6, 0.5):\n",
    "    for e in (0.01, 0.02, 0.03, 0.04, 0.05):\n",
    "        model = NeuralNetwork().to(device)\n",
    "        train_model_ibp(model, 1, e, k)\n",
    "        print('kappa: ',k, ' eps: ', e)\n",
    "        standard_test(model, device, test_loader)\n",
    "        find_robustness(model, attack='pgd', eps=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e417ad1-2988-45f7-997d-40a3fb61e7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c0fb9-7186-4c4c-8f2d-ab44ad16d4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
